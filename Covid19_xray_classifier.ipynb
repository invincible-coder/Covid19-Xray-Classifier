{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid19-xray-classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOwEUqFqZGDj",
        "colab_type": "text"
      },
      "source": [
        "**Covid-19 x-ray**(images) **classification** (Binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_07CuG9tY1-u",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Load images if saved in drive as follows:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWv356cTmMe_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCBE5DjCY1Pi",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Loading images from folder as given under dataset folder\n",
        "\n",
        "\n",
        "> positive examples\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> neglect code before /dataset if in same directory\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff2UXyMPuEjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "folder='/content/drive/My Drive/dataset/train/1'\n",
        "images = np.zeros((163,224,224,3),dtype=float)\n",
        "k=0\n",
        "for filename in os.listdir(folder):\n",
        "  img = Image.open(os.path.join(folder,filename)).convert(\"RGB\")\n",
        "  img=img.resize((224,224),PIL.Image.ANTIALIAS)\n",
        "  if img is not None:\n",
        "    images[k]=img\n",
        "    images[k]=images[k]\n",
        "    k=k+1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnRE88rQagX4",
        "colab_type": "text"
      },
      "source": [
        "> Loading images from folder as given under dataset folder\n",
        "\n",
        "> negative examples\n",
        "\n",
        "> neglect code before /dataset if in same directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8NF3P1yy8zk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder='/content/drive/My Drive/dataset/train/0'\n",
        "for filename in os.listdir(folder):\n",
        "  img = Image.open(os.path.join(folder,filename)).convert(\"RGB\")\n",
        "  img=img.resize((224,224),PIL.Image.ANTIALIAS)\n",
        "  if img is not None:\n",
        "      images[k]=img\n",
        "      images[k]=images[k]\n",
        "      k=k+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOQI1QBOa22E",
        "colab_type": "text"
      },
      "source": [
        ">Creating labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaFSOokhw79_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y1=np.ones((83))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMVpKypQxWwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y2=np.zeros((80))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnOHwL_-0KZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=np.concatenate((y1,y2),axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd777QSg0iZc",
        "colab_type": "code",
        "outputId": "b7b104a9-1a6b-4d22-94e2-c4d2c2356a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(163,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o7Msgg2a_Y8",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        ">Shuffling data to generalise model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umy4H8pQ0p71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "x,y=shuffle(images,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlPICnQ_bIYN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Splitting data into train and validation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pST3MqD1EqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10ZbHIuC1drj",
        "colab_type": "code",
        "outputId": "c35b3d15-cf68-4cf8-cef9-2bdae75fd391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2)\n",
        "print (X_train.shape, y_train.shape)\n",
        "print (X_val.shape, y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(130, 224, 224, 3) (130,)\n",
            "(33, 224, 224, 3) (33,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY5OKhETbZtQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Model for training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlUvHKGIFUVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (7,7), activation='relu',input_shape=(224,224,3)),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    \n",
        "      tf.keras.layers.Conv2D(64, (5,5), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D((2,2)),\n",
        "      \n",
        "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.25),\n",
        "      tf.keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "lrr=0.001\n",
        "epochs=200\n",
        "model.compile(optimizer =tf.keras.optimizers.SGD(lr=lrr,momentum=0.9,clipnorm=1.),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pP_IHA9bhUq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Image Data augmentation to generalise model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J6i7y4mb-RU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Learning rate scheduler for better accuracy \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLsLJzdvFUKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,\n",
        "                 shear_range=0.05,\n",
        "                 zoom_range=0.05,\n",
        "                 channel_shift_range=0.,\n",
        "                 fill_mode='nearest',\n",
        "                 cval=0.,\n",
        "                 horizontal_flip=True,\n",
        "                 rescale=1/255.0)\n",
        "\n",
        "datagen.fit(X_train)\n",
        "d_val=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.0)\n",
        "d_val.fit(X_val)\n",
        "\n",
        "def scheduler(epoch):\n",
        "  return 0.001 * tf.math.exp(-0.1 * epoch)\n",
        "\n",
        "lms = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSLfO-L8cIgE",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Early stopping , saving model whenever val-accuracy increases and reducing learning rate once val-loss becomes flat \n",
        "\n",
        "> Fitting model (run this block twice continously to improve accuracy )\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPXs4QxrFT-v",
        "colab_type": "code",
        "outputId": "e827a783-42f6-4b20-8193-426ab98877df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "earlystopping =tf.keras.callbacks. EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=30, mode='auto')\n",
        "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, mode='auto')\n",
        "ch=tf.keras.callbacks.ModelCheckpoint('save.h5',monitor='val_accuracy',verbose=1,save_best_only=True,mode='auto')\n",
        "history=model.fit_generator(datagen.flow(X_train, y_train, batch_size=32),\n",
        "                    steps_per_epoch=len(X_train) / 32,epochs=200,validation_data=(X_val,y_val),shuffle=True,callbacks=[ch, earlystopping,lms,reduceLR])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.3102 - accuracy: 0.8906\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.90909, saving model to m6.h5\n",
            "5/4 [====================================] - 1s 255ms/step - loss: 0.2747 - accuracy: 0.8923 - val_loss: 7.2358 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.2601 - accuracy: 0.8984\n",
            "Epoch 00002: val_accuracy improved from 0.90909 to 0.96970, saving model to m6.h5\n",
            "5/4 [====================================] - 1s 255ms/step - loss: 0.2711 - accuracy: 0.9000 - val_loss: 6.3275 - val_accuracy: 0.9697 - lr: 9.0484e-04\n",
            "Epoch 3/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.3112 - accuracy: 0.8750\n",
            "Epoch 00003: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 228ms/step - loss: 0.3198 - accuracy: 0.8692 - val_loss: 7.1865 - val_accuracy: 0.9091 - lr: 8.1873e-04\n",
            "Epoch 4/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.3673 - accuracy: 0.8594\n",
            "Epoch 00004: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 227ms/step - loss: 0.4078 - accuracy: 0.8615 - val_loss: 10.5458 - val_accuracy: 0.9091 - lr: 7.4082e-04\n",
            "Epoch 5/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.3382 - accuracy: 0.8438\n",
            "Epoch 00005: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 223ms/step - loss: 0.3611 - accuracy: 0.8385 - val_loss: 7.6631 - val_accuracy: 0.9697 - lr: 6.7032e-04\n",
            "Epoch 6/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.2475 - accuracy: 0.9141\n",
            "Epoch 00006: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 223ms/step - loss: 0.2103 - accuracy: 0.9154 - val_loss: 7.2295 - val_accuracy: 0.9697 - lr: 6.0653e-04\n",
            "Epoch 7/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.2539 - accuracy: 0.8984\n",
            "Epoch 00007: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 232ms/step - loss: 0.2074 - accuracy: 0.9000 - val_loss: 8.0489 - val_accuracy: 0.9394 - lr: 5.4881e-04\n",
            "Epoch 8/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.2287 - accuracy: 0.9062\n",
            "Epoch 00008: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 226ms/step - loss: 0.2181 - accuracy: 0.9077 - val_loss: 8.0857 - val_accuracy: 0.9697 - lr: 4.9659e-04\n",
            "Epoch 9/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.2229 - accuracy: 0.9375\n",
            "Epoch 00009: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 227ms/step - loss: 0.2305 - accuracy: 0.9385 - val_loss: 10.4032 - val_accuracy: 0.9091 - lr: 4.4933e-04\n",
            "Epoch 10/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.2940 - accuracy: 0.9062\n",
            "Epoch 00010: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 226ms/step - loss: 0.2450 - accuracy: 0.9077 - val_loss: 9.6994 - val_accuracy: 0.9091 - lr: 4.0657e-04\n",
            "Epoch 11/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.1915 - accuracy: 0.9297\n",
            "Epoch 00011: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 226ms/step - loss: 0.1695 - accuracy: 0.9308 - val_loss: 11.5948 - val_accuracy: 0.9091 - lr: 3.6788e-04\n",
            "Epoch 12/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.2110 - accuracy: 0.9141\n",
            "Epoch 00012: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 226ms/step - loss: 0.1783 - accuracy: 0.9154 - val_loss: 9.1895 - val_accuracy: 0.9394 - lr: 3.3287e-04\n",
            "Epoch 13/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.2293 - accuracy: 0.8906\n",
            "Epoch 00013: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 228ms/step - loss: 0.1932 - accuracy: 0.8923 - val_loss: 9.2549 - val_accuracy: 0.9697 - lr: 3.0119e-04\n",
            "Epoch 14/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.1802 - accuracy: 0.9375\n",
            "Epoch 00014: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 232ms/step - loss: 0.1458 - accuracy: 0.9385 - val_loss: 9.2722 - val_accuracy: 0.9697 - lr: 2.7253e-04\n",
            "Epoch 15/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.1864 - accuracy: 0.9453\n",
            "Epoch 00015: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 227ms/step - loss: 0.1519 - accuracy: 0.9462 - val_loss: 8.9509 - val_accuracy: 0.9394 - lr: 2.4660e-04\n",
            "Epoch 16/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.2433 - accuracy: 0.9219\n",
            "Epoch 00016: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 227ms/step - loss: 0.1989 - accuracy: 0.9231 - val_loss: 8.9446 - val_accuracy: 0.9394 - lr: 2.2313e-04\n",
            "Epoch 17/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.1695 - accuracy: 0.9375\n",
            "Epoch 00017: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 223ms/step - loss: 0.1554 - accuracy: 0.9385 - val_loss: 8.6512 - val_accuracy: 0.9697 - lr: 2.0190e-04\n",
            "Epoch 18/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.2320 - accuracy: 0.9141\n",
            "Epoch 00018: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 221ms/step - loss: 0.3249 - accuracy: 0.9077 - val_loss: 8.8304 - val_accuracy: 0.9697 - lr: 1.8268e-04\n",
            "Epoch 19/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.1925 - accuracy: 0.9531\n",
            "Epoch 00019: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 226ms/step - loss: 0.1570 - accuracy: 0.9538 - val_loss: 9.1582 - val_accuracy: 0.9697 - lr: 1.6530e-04\n",
            "Epoch 20/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.2077 - accuracy: 0.9375\n",
            "Epoch 00020: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 223ms/step - loss: 0.3077 - accuracy: 0.9308 - val_loss: 8.4994 - val_accuracy: 0.9697 - lr: 1.4957e-04\n",
            "Epoch 21/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.1973 - accuracy: 0.9375\n",
            "Epoch 00021: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 225ms/step - loss: 0.1744 - accuracy: 0.9385 - val_loss: 7.8242 - val_accuracy: 0.9697 - lr: 1.3534e-04\n",
            "Epoch 22/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.2428 - accuracy: 0.9297\n",
            "Epoch 00022: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 227ms/step - loss: 0.2110 - accuracy: 0.9308 - val_loss: 8.6479 - val_accuracy: 0.9091 - lr: 1.2246e-04\n",
            "Epoch 23/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.2068 - accuracy: 0.9297\n",
            "Epoch 00023: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 224ms/step - loss: 0.1660 - accuracy: 0.9308 - val_loss: 8.3950 - val_accuracy: 0.9091 - lr: 1.1080e-04\n",
            "Epoch 24/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.1673 - accuracy: 0.9453\n",
            "Epoch 00024: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 225ms/step - loss: 0.1580 - accuracy: 0.9462 - val_loss: 8.1573 - val_accuracy: 0.9697 - lr: 1.0026e-04\n",
            "Epoch 25/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.1780 - accuracy: 0.9531\n",
            "Epoch 00025: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 223ms/step - loss: 0.4195 - accuracy: 0.9462 - val_loss: 8.8091 - val_accuracy: 0.9697 - lr: 9.0718e-05\n",
            "Epoch 26/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.2023 - accuracy: 0.9297\n",
            "Epoch 00026: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 223ms/step - loss: 0.1669 - accuracy: 0.9308 - val_loss: 8.7689 - val_accuracy: 0.9697 - lr: 8.2085e-05\n",
            "Epoch 27/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.1773 - accuracy: 0.9531\n",
            "Epoch 00027: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 233ms/step - loss: 0.1490 - accuracy: 0.9538 - val_loss: 8.6180 - val_accuracy: 0.9697 - lr: 7.4274e-05\n",
            "Epoch 28/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.1898 - accuracy: 0.9453\n",
            "Epoch 00028: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 223ms/step - loss: 0.1536 - accuracy: 0.9462 - val_loss: 8.4220 - val_accuracy: 0.9697 - lr: 6.7206e-05\n",
            "Epoch 29/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.1791 - accuracy: 0.9531\n",
            "Epoch 00029: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 227ms/step - loss: 0.1466 - accuracy: 0.9538 - val_loss: 8.2955 - val_accuracy: 0.9697 - lr: 6.0810e-05\n",
            "Epoch 30/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.1806 - accuracy: 0.9375\n",
            "Epoch 00030: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 227ms/step - loss: 0.1563 - accuracy: 0.9385 - val_loss: 8.3114 - val_accuracy: 0.9697 - lr: 5.5023e-05\n",
            "Epoch 31/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.1805 - accuracy: 0.9219\n",
            "Epoch 00031: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 224ms/step - loss: 0.1550 - accuracy: 0.9231 - val_loss: 8.4780 - val_accuracy: 0.9697 - lr: 4.9787e-05\n",
            "Epoch 32/200\n",
            "4/4 [============================>.] - ETA: 0s - loss: 0.1605 - accuracy: 0.9453\n",
            "Epoch 00032: val_accuracy did not improve from 0.96970\n",
            "5/4 [====================================] - 1s 226ms/step - loss: 0.1334 - accuracy: 0.9462 - val_loss: 8.6804 - val_accuracy: 0.9697 - lr: 4.5049e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3KniooEc3he",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Load the saved model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9q4IZjIEDHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nmodel=tf.keras.models.load_model('save.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-uDHqHFc_nE",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Load test images same as in training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDxxQpK94-ES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder='/content/drive/My Drive/dataset/test'\n",
        "test = np.zeros((24,224,224,3),dtype=int)\n",
        "k=0\n",
        "for filename in os.listdir(folder):\n",
        "  img = Image.open(os.path.join(folder,filename)).convert(\"RGB\")\n",
        "  img=img.resize((224,224),PIL.Image.ANTIALIAS)\n",
        "  if img is not None:\n",
        "      test[k]=img\n",
        "      test[k]=test[k]\n",
        "      k=k+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy4cLoysdI5X",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Normalise test images and make predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDT4PPLv3OVv",
        "colab_type": "code",
        "outputId": "371362e2-4393-4d64-ad1a-948ba5198153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "d_val.fit(test)\n",
        "tsp=[]\n",
        "tsp.append(['image','label'])\n",
        "i=0\n",
        "for filename in os.listdir(folder):\n",
        "    tsp.append([filename,int(nmodel.predict_classes(test[i].reshape((1,224,224,3))))])\n",
        "    i=i+1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-58de958c35ed>:6: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0G_mONWdPSt",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Save predictions in a csv file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muWHc4wo47rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "with open(\"/test_predic001.csv\",\"w\") as f:\n",
        "    writer=csv.writer(f,delimiter=',',lineterminator='\\n')\n",
        "    writer.writerows(tsp)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}